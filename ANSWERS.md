
1) Первый вариант проще, так как результат первого выражения не зависит от предыдущих значений `y[i]`, что сильно ухудшает параллелизм задачи.
В то время как в первом варианте результат каждого `y[i]` зависит только от входных значений, что позволяет вычислять каждый `y[i]` независимо. 


2) Не произойдет.  
Так как `get_local_size(1) * get_local_id(0)` всегда кратно 32 из-за того, `get_local_size(1) == 32`, а `get_local_id(1)` при `WAVE_SIZE == 32` у всех потоков волны будет всегда одинаковый, потому что wg_size = (32, 32, 1), а потоки отсчитываются по волнам в порядке x, y, z. 


3) Ответы: 

(a) Да, *coalesced*. Все 32 потока в *warp*'e читают элементы последовательно, так как `threadId = get_local_id(0) + get_local_size(0) * get_local_id(1)` это последовательность от `[0:1023]`. При этом каждая волна будет просить выравненный кусок данных размеров - `sizeof(float) * WAVE_SIZE = 128` байт, что ровно размеры кэш-линии, что значит, что каждая волна потрогает по одной линии кэша. Для WG это будет `1 линия * 32 волны = 32 линии`.

(b) Если в пункте (a) `threadId` для матрицы (32, 32) выдавались сначала по строкам, а потом по колонкам, то в этом варианте все наоборот. Каждая волна грузит колонку матрицы, где размер одной строки это 128 байт, что значит, что одна строка матрицы это один кэш-лайн -> если наша волна за одну memory транзакцию пытается потрогать 32 строки, то она потрогает 32 кэш-лайна. Для WG это будет `32 линии * 32 волны = 1024 линии`. Получается, что не *coalesced*.

(с) Это вариант (a) со сдвигом один, что значит, что теперь каждая волна из-за сдвига трогает два кэш-лайна. WG - `2 * 32 = 64` лайна кэша. Поскольку волна все еще обращается по смежным адресам в памяти, то это обращение считается `coalesced` 
